{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Multi-Agent Sandbox\n",
    "\n",
    "This notebook provides a testing environment for the Simplify Agent, which uses LangGraph to create a multi-step workflow for simplifying complex topics.\n",
    "\n",
    "**Architecture Overview:**\n",
    "- **State Management**: Defines the graph state and structured output schema\n",
    "- **Model Configuration**: Sets up the LLM with structured output binding\n",
    "- **Agent Graph**: Builds the LangGraph workflow with nodes and edges\n",
    "- **Execution**: Runs the agent with test topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration & Environment Setup\n",
    "\n",
    "Load environment variables and configure the OpenAI API key and model settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "LLM_MODEL = \"gpt-4o-mini\"  # Using a valid model\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "print(f\"‚úì Configuration loaded\")\n",
    "print(f\"‚úì Model: {LLM_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. State Management & Schema Definition\n",
    "\n",
    "Define the Pydantic schema for structured output and the graph state that flows through the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# --- Structured Output Schema ---\n",
    "class TopicSummary(BaseModel):\n",
    "    \"\"\"\n",
    "    Schema for the final, structured output of the agent.\n",
    "    This ensures the LLM's response is easily parsable and high-quality.\n",
    "    \"\"\"\n",
    "    topic: str = Field(description=\"The original topic provided by the user.\")\n",
    "    simplified_text: str = Field(\n",
    "        description=\"A clear, simple explanation of the topic, suitable for a 10-year-old.\"\n",
    "    )\n",
    "    analogy: str = Field(\n",
    "        description=\"A simple, relatable analogy to explain the core concept.\"\n",
    "    )\n",
    "    example: str = Field(\n",
    "        description=\"A real-world or fictional example that illustrates the topic.\"\n",
    "    )\n",
    "\n",
    "# --- Graph State ---\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of the graph's execution.\n",
    "    Data flow across nodes is managed by updating this dictionary.\n",
    "    \"\"\"\n",
    "    # The complex topic provided by the user\n",
    "    user_topic: str\n",
    "    # The final, structured output from the LLM\n",
    "    final_summary: Optional[TopicSummary]\n",
    "\n",
    "print(\"‚úì State classes defined\")\n",
    "print(f\"‚úì TopicSummary fields: {list(TopicSummary.model_fields.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model & Prompt Configuration\n",
    "\n",
    "Initialize the LLM with structured output binding and define the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def get_llm_with_schema():\n",
    "    \"\"\"\n",
    "    Initializes the LLM and binds it to the TopicSummary Pydantic schema\n",
    "    to ensure the output is structured JSON.\n",
    "    \"\"\"\n",
    "    # Initialize the LLM client\n",
    "    llm = ChatOpenAI(\n",
    "        model=LLM_MODEL,\n",
    "        api_key=OPENAI_API_KEY,\n",
    "        temperature=0.2  # Slight temperature for creative parts like analogy/example\n",
    "    )\n",
    "\n",
    "    # Bind the Pydantic schema to the LLM\n",
    "    # This instructs the model to generate a JSON object matching the schema\n",
    "    llm_with_schema = llm.with_structured_output(TopicSummary)\n",
    "    return llm_with_schema\n",
    "\n",
    "def get_summary_prompt():\n",
    "    \"\"\"\n",
    "    Defines the system prompt to guide the LLM's persona and task.\n",
    "    \"\"\"\n",
    "    system_prompt = (\n",
    "        \"You are an expert science communicator and educator. Your goal is to \"\n",
    "        \"take a complex topic and explain it in a clear, highly structured, \"\n",
    "        \"and engaging manner. You must output a JSON object that strictly \"\n",
    "        \"adheres to the provided schema. Do not output any text other than the JSON.\"\n",
    "    )\n",
    "    \n",
    "    # Placeholder for the user's input topic\n",
    "    human_template = \"Topic to explain: {user_topic}\"\n",
    "\n",
    "    return ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", human_template)\n",
    "    ])\n",
    "\n",
    "# Initialize\n",
    "llm_with_schema = get_llm_with_schema()\n",
    "summary_prompt = get_summary_prompt()\n",
    "\n",
    "print(\"‚úì LLM initialized with structured output\")\n",
    "print(\"‚úì Prompt template created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph Nodes & Edge Logic\n",
    "\n",
    "Define the nodes (processing steps) and edge logic (routing decisions) for the LangGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.exceptions import OutputParserException\n",
    "\n",
    "# --- Graph Nodes ---\n",
    "\n",
    "def generate_summary_node(state: GraphState) -> dict:\n",
    "    \"\"\"\n",
    "    Calls the LLM with the structured output schema to generate the summary.\n",
    "    This node attempts to produce the final, structured output.\n",
    "    \"\"\"\n",
    "    print(f\"--- Running Node: Generate Summary for '{state['user_topic']}' ---\")\n",
    "    \n",
    "    # The state is used as the input variables for the prompt\n",
    "    chain = summary_prompt | llm_with_schema\n",
    "    \n",
    "    try:\n",
    "        # Invoke the chain, which forces structured JSON output\n",
    "        result: TopicSummary = chain.invoke(state)\n",
    "        print(\"Summary generated successfully.\")\n",
    "        \n",
    "        # Update the state with the final structured result\n",
    "        return {\"final_summary\": result}\n",
    "        \n",
    "    except OutputParserException as e:\n",
    "        # If the LLM fails to produce valid JSON, handle the error\n",
    "        print(f\"Error: OutputParserException encountered: {e}\")\n",
    "        # Optionally, you could add logic here to re-prompt the LLM\n",
    "        # For this simple example, we will stop and report the error.\n",
    "        return {\"final_summary\": None}\n",
    "\n",
    "\n",
    "# --- Graph Edges (Router) ---\n",
    "\n",
    "def decide_to_end(state: GraphState) -> str:\n",
    "    \"\"\"\n",
    "    A router function that determines the next step.\n",
    "    Since this is a simple, single-step agent, it always proceeds to END.\n",
    "    \"\"\"\n",
    "    print(\"--- Running Router: Decide to End ---\")\n",
    "    \n",
    "    if state.get(\"final_summary\"):\n",
    "        # If we have a summary, we are done\n",
    "        return \"end\"\n",
    "    else:\n",
    "        # If the summary failed to generate (e.g., due to parsing error), we also stop\n",
    "        return \"end\"\n",
    "\n",
    "print(\"‚úì Graph nodes and edge logic defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the LangGraph Workflow\n",
    "\n",
    "Assemble all components into a compiled LangGraph application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def build_agent_graph():\n",
    "    \"\"\"\n",
    "    Assembles the LangGraph workflow. \n",
    "    \"\"\"\n",
    "    print(\"--- Building LangGraph Agent ---\")\n",
    "    \n",
    "    # 1. Define the graph state\n",
    "    workflow = StateGraph(GraphState)\n",
    "\n",
    "    # 2. Add nodes\n",
    "    # The main node is the only step that generates content\n",
    "    workflow.add_node(\"summary_generator\", generate_summary_node)\n",
    "\n",
    "    # 3. Set the entry point (first node to run)\n",
    "    workflow.set_entry_point(\"summary_generator\")\n",
    "\n",
    "    # 4. Add the edge to the router\n",
    "    # After the summary is generated, we call the router to decide the next step\n",
    "    workflow.add_conditional_edges(\n",
    "        \"summary_generator\",\n",
    "        decide_to_end,\n",
    "        {\n",
    "            \"end\": END,  # If the router returns \"end\", stop the graph\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 5. Compile the graph into a runnable application\n",
    "    app = workflow.compile()\n",
    "    print(\"--- LangGraph Agent Compiled ---\")\n",
    "    return app\n",
    "\n",
    "# Compile the final agent application\n",
    "agent_app = build_agent_graph()\n",
    "\n",
    "print(\"‚úì Agent graph compiled and ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize the Graph (Optional)\n",
    "\n",
    "Display the graph structure using Mermaid or ASCII representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to visualize the graph\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(agent_app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph visualization: {e}\")\n",
    "    print(\"\\nGraph structure (text):\")\n",
    "    print(agent_app.get_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Execution - Simple Topic\n",
    "\n",
    "Run the agent with a simple test topic to verify the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(topic: str):\n",
    "    \"\"\"\n",
    "    Runs the compiled LangGraph agent with a specific topic.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Starting Agent for Topic: '{topic}' ---\")\n",
    "\n",
    "    # The initial state contains only the user's topic\n",
    "    initial_state: GraphState = {\"user_topic\": topic, \"final_summary\": None}\n",
    "\n",
    "    # Invoke the agent\n",
    "    final_state: GraphState = agent_app.invoke(initial_state)\n",
    "\n",
    "    # --- Print Final Output ---\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"--- FINAL RESULT ---\")\n",
    "    \n",
    "    summary: Optional[TopicSummary] = final_state.get(\"final_summary\")\n",
    "    \n",
    "    if summary:\n",
    "        print(f\"Topic: {summary.topic}\")\n",
    "        print(\"\\n--- Simplified Text ---\")\n",
    "        print(summary.simplified_text)\n",
    "        print(\"\\n--- Analogy ---\")\n",
    "        print(summary.analogy)\n",
    "        print(\"\\n--- Example ---\")\n",
    "        print(summary.example)\n",
    "    else:\n",
    "        print(\"Agent failed to produce a structured summary. Check logs for errors.\")\n",
    "\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Test with a simple topic\n",
    "test_topic_1 = \"Photosynthesis\"\n",
    "result_1 = run_agent(test_topic_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Human-in-the-Loop Feedback System\n",
    "\n",
    "This section implements an interactive feedback loop where you can:\n",
    "- Review generated explanations\n",
    "- Approve with \"yes\" or request regeneration with \"regenerate\"\n",
    "- Track conversation history across attempts\n",
    "- See improvements with each iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Enhanced State with Conversation History\n",
    "\n",
    "Extend the graph state to track feedback and previous attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì FeedbackGraphState defined\n",
      "‚úì New fields: conversation_history, feedback, attempt_count, max_attempts, user_notes\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Optional, List, Dict, Any\n",
    "\n",
    "# Enhanced state for feedback loop\n",
    "class FeedbackGraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Extended state that includes conversation history and feedback.\n",
    "    \"\"\"\n",
    "    # Original fields\n",
    "    user_topic: str\n",
    "    final_summary: Optional[TopicSummary]\n",
    "    \n",
    "    # New fields for feedback loop\n",
    "    conversation_history: List[Dict[str, Any]]  # List of previous attempts\n",
    "    feedback: Optional[str]  # \"yes\" or \"regenerate\"\n",
    "    attempt_count: int  # Current attempt number\n",
    "    max_attempts: int  # Maximum regeneration attempts\n",
    "    user_notes: Optional[str]  # Optional feedback on what to improve\n",
    "\n",
    "print(\"‚úì FeedbackGraphState defined\")\n",
    "print(\"‚úì New fields: conversation_history, feedback, attempt_count, max_attempts, user_notes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Graph Nodes with Feedback Logic\n",
    "\n",
    "Define nodes that handle generation with context and human feedback collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Feedback nodes defined\n"
     ]
    }
   ],
   "source": [
    "def generate_summary_with_history_node(state: FeedbackGraphState) -> dict:\n",
    "    \"\"\"\n",
    "    Generates a summary with context from previous attempts.\n",
    "    If this is a regeneration, the prompt includes feedback from previous attempts.\n",
    "    \"\"\"\n",
    "    attempt_num = state['attempt_count'] + 1\n",
    "    print(f\"\\n--- Attempt #{attempt_num}: Generating Summary for '{state['user_topic']}' ---\")\n",
    "    \n",
    "    # Build the prompt based on whether this is a regeneration\n",
    "    if state['conversation_history']:\n",
    "        # This is a regeneration - include context from previous attempts\n",
    "        previous_attempts = state['conversation_history']\n",
    "        \n",
    "        # Create an enhanced prompt with context\n",
    "        context_info = f\"\\n\\nPREVIOUS ATTEMPTS ({len(previous_attempts)}):\" \n",
    "        for i, attempt in enumerate(previous_attempts, 1):\n",
    "            context_info += f\"\\n\\nAttempt {i}:\"\n",
    "            context_info += f\"\\n- Simplified: {attempt['summary'].simplified_text[:100]}...\"\n",
    "            context_info += f\"\\n- Analogy: {attempt['summary'].analogy[:100]}...\"\n",
    "        \n",
    "        context_info += \"\\n\\nPlease generate a NEW explanation that improves upon the previous attempts. \"\n",
    "        context_info += \"Use different analogies, examples, and explanations. Make it more engaging and clearer.\"\n",
    "        \n",
    "        # Enhanced prompt for regeneration\n",
    "        from langchain_core.prompts import ChatPromptTemplate\n",
    "        enhanced_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", (\n",
    "                \"You are an expert science communicator. The user was not satisfied with previous explanations. \"\n",
    "                \"Generate a BETTER explanation with fresh perspectives, different analogies, and clearer examples. \"\n",
    "                \"Output only valid JSON matching the schema.\"\n",
    "            )),\n",
    "            (\"human\", \"Topic: {user_topic}\" + context_info)\n",
    "        ])\n",
    "        \n",
    "        chain = enhanced_prompt | llm_with_schema\n",
    "    else:\n",
    "        # First attempt - use standard prompt\n",
    "        chain = summary_prompt | llm_with_schema\n",
    "    \n",
    "    try:\n",
    "        # Generate the summary\n",
    "        result: TopicSummary = chain.invoke(state)\n",
    "        print(f\"‚úì Summary generated successfully (Attempt #{attempt_num})\")\n",
    "        \n",
    "        # Add to conversation history\n",
    "        new_history = state['conversation_history'].copy()\n",
    "        new_history.append({\n",
    "            'attempt': attempt_num,\n",
    "            'summary': result,\n",
    "            'feedback': None  # Will be filled in by human feedback node\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"final_summary\": result,\n",
    "            \"conversation_history\": new_history,\n",
    "            \"attempt_count\": attempt_num\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating summary: {e}\")\n",
    "        return {\"final_summary\": None}\n",
    "\n",
    "\n",
    "def human_feedback_node(state: FeedbackGraphState) -> dict:\n",
    "    \"\"\"\n",
    "    Collects human feedback on the generated summary.\n",
    "    Asks the user to approve (yes) or request regeneration (regenerate).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìã GENERATED EXPLANATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    summary = state['final_summary']\n",
    "    if summary:\n",
    "        print(f\"\\nüéØ Topic: {summary.topic}\")\n",
    "        print(f\"\\nüìù Simplified Explanation:\\n{summary.simplified_text}\")\n",
    "        print(f\"\\nüîÑ Analogy:\\n{summary.analogy}\")\n",
    "        print(f\"\\nüí° Example:\\n{summary.example}\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå No summary was generated.\")\n",
    "        return {\"feedback\": \"end\"}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Attempt {state['attempt_count']} of {state['max_attempts']}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get user feedback\n",
    "    while True:\n",
    "        user_input = input(\"\\nüëâ Enter 'yes' to approve or 'regenerate' to try again: \").strip().lower()\n",
    "        \n",
    "        if user_input in ['yes', 'y']:\n",
    "            print(\"\\n‚úÖ Explanation approved!\")\n",
    "            # Update the last history entry with feedback\n",
    "            updated_history = state['conversation_history'].copy()\n",
    "            if updated_history:\n",
    "                updated_history[-1]['feedback'] = 'approved'\n",
    "            return {\n",
    "                \"feedback\": \"yes\",\n",
    "                \"conversation_history\": updated_history\n",
    "            }\n",
    "        \n",
    "        elif user_input in ['regenerate', 'r', 'no', 'n']:\n",
    "            # Optional: ask what to improve\n",
    "            notes = input(\"\\nüí≠ (Optional) What should be improved? Press Enter to skip: \").strip()\n",
    "            \n",
    "            print(\"\\nüîÑ Regenerating with improvements...\")\n",
    "            # Update the last history entry with feedback\n",
    "            updated_history = state['conversation_history'].copy()\n",
    "            if updated_history:\n",
    "                updated_history[-1]['feedback'] = 'regenerate'\n",
    "                if notes:\n",
    "                    updated_history[-1]['user_notes'] = notes\n",
    "            \n",
    "            return {\n",
    "                \"feedback\": \"regenerate\",\n",
    "                \"user_notes\": notes if notes else None,\n",
    "                \"conversation_history\": updated_history\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            print(\"‚ùå Invalid input. Please enter 'yes' or 'regenerate'.\")\n",
    "\n",
    "print(\"‚úì Feedback nodes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Routing Logic\n",
    "\n",
    "Define how the graph routes based on user feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Routing logic defined\n"
     ]
    }
   ],
   "source": [
    "def route_after_feedback(state: FeedbackGraphState) -> str:\n",
    "    \"\"\"\n",
    "    Routes the graph based on user feedback.\n",
    "    - 'yes' ‚Üí END (user approved)\n",
    "    - 'regenerate' ‚Üí generate_summary (try again)\n",
    "    - Check max attempts to prevent infinite loops\n",
    "    \"\"\"\n",
    "    feedback = state.get('feedback')\n",
    "    attempt_count = state.get('attempt_count', 0)\n",
    "    max_attempts = state.get('max_attempts', 3)\n",
    "    \n",
    "    print(f\"\\n--- Router: Processing feedback '{feedback}' (Attempt {attempt_count}/{max_attempts}) ---\")\n",
    "    \n",
    "    # If user approved, end the workflow\n",
    "    if feedback == 'yes':\n",
    "        print(\"‚Üí Routing to END (approved)\")\n",
    "        return \"end\"\n",
    "    \n",
    "    # If user wants to regenerate\n",
    "    elif feedback == 'regenerate':\n",
    "        # Check if we've hit max attempts\n",
    "        if attempt_count >= max_attempts:\n",
    "            print(f\"‚ö†Ô∏è  Maximum attempts ({max_attempts}) reached. Ending workflow.\")\n",
    "            return \"end\"\n",
    "        else:\n",
    "            print(\"‚Üí Routing back to GENERATE (regenerate)\")\n",
    "            return \"regenerate\"\n",
    "    \n",
    "    # Default: end\n",
    "    else:\n",
    "        print(\"‚Üí Routing to END (default)\")\n",
    "        return \"end\"\n",
    "\n",
    "print(\"‚úì Routing logic defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Build the Feedback Loop Graph\n",
    "\n",
    "Assemble the graph with feedback loop capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Building Feedback Loop Agent ---\n",
      "‚úì Feedback Loop Agent compiled\n",
      "\n",
      "‚úÖ Feedback agent ready to use!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "def build_feedback_agent_graph():\n",
    "    \"\"\"\n",
    "    Builds a LangGraph workflow with human-in-the-loop feedback.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Building Feedback Loop Agent ---\")\n",
    "    \n",
    "    # 1. Create the graph with FeedbackGraphState\n",
    "    workflow = StateGraph(FeedbackGraphState)\n",
    "    \n",
    "    # 2. Add nodes\n",
    "    workflow.add_node(\"generate_summary\", generate_summary_with_history_node)\n",
    "    workflow.add_node(\"human_feedback\", human_feedback_node)\n",
    "    \n",
    "    # 3. Set entry point\n",
    "    workflow.set_entry_point(\"generate_summary\")\n",
    "    \n",
    "    # 4. Add edges\n",
    "    # After generation, always go to human feedback\n",
    "    workflow.add_edge(\"generate_summary\", \"human_feedback\")\n",
    "    \n",
    "    # After feedback, route based on user input\n",
    "    workflow.add_conditional_edges(\n",
    "        \"human_feedback\",\n",
    "        route_after_feedback,\n",
    "        {\n",
    "            \"end\": END,\n",
    "            \"regenerate\": \"generate_summary\"  # Loop back!\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # 5. Compile\n",
    "    app = workflow.compile()\n",
    "    print(\"‚úì Feedback Loop Agent compiled\")\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Build the feedback agent\n",
    "feedback_agent = build_feedback_agent_graph()\n",
    "\n",
    "print(\"\\n‚úÖ Feedback agent ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Visualize the Feedback Loop\n",
    "\n",
    "See the graph structure with the feedback loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the feedback graph\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(feedback_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"\\nGraph structure:\")\n",
    "    print(feedback_agent.get_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 Run the Feedback Loop Agent\n",
    "\n",
    "Test the agent with human-in-the-loop feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Interactive testing function ready\n",
      "\n",
      "üí° Usage: run_agent_with_feedback('Your Topic Here', max_attempts=3)\n"
     ]
    }
   ],
   "source": [
    "def run_agent_with_feedback(topic: str, max_attempts: int = 3):\n",
    "    \"\"\"\n",
    "    Runs the feedback loop agent with a given topic.\n",
    "    \n",
    "    Args:\n",
    "        topic: The complex topic to simplify\n",
    "        max_attempts: Maximum number of regeneration attempts (default: 3)\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üöÄ STARTING FEEDBACK LOOP AGENT\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Topic: {topic}\")\n",
    "    print(f\"Max Attempts: {max_attempts}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Initialize state\n",
    "    initial_state: FeedbackGraphState = {\n",
    "        \"user_topic\": topic,\n",
    "        \"final_summary\": None,\n",
    "        \"conversation_history\": [],\n",
    "        \"feedback\": None,\n",
    "        \"attempt_count\": 0,\n",
    "        \"max_attempts\": max_attempts,\n",
    "        \"user_notes\": None\n",
    "    }\n",
    "    \n",
    "    # Run the agent\n",
    "    final_state: FeedbackGraphState = feedback_agent.invoke(initial_state)\n",
    "    \n",
    "    # Display final results\n",
    "    print(\"\\n\\n\" + \"=\"*70)\n",
    "    print(\"üìä FINAL RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\n‚úì Total Attempts: {final_state['attempt_count']}\")\n",
    "    print(f\"‚úì Final Decision: {final_state.get('feedback', 'N/A')}\")\n",
    "    \n",
    "    # Show conversation history\n",
    "    if final_state['conversation_history']:\n",
    "        print(f\"\\nüìú CONVERSATION HISTORY:\\n\")\n",
    "        for entry in final_state['conversation_history']:\n",
    "            print(f\"  Attempt {entry['attempt']}:\")\n",
    "            print(f\"    Feedback: {entry.get('feedback', 'N/A')}\")\n",
    "            if entry.get('user_notes'):\n",
    "                print(f\"    Notes: {entry['user_notes']}\")\n",
    "            print()\n",
    "    \n",
    "    # Show final approved summary\n",
    "    if final_state.get('final_summary'):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"‚úÖ APPROVED EXPLANATION\")\n",
    "        print(\"=\"*70)\n",
    "        summary = final_state['final_summary']\n",
    "        print(f\"\\nüéØ Topic: {summary.topic}\")\n",
    "        print(f\"\\nüìù Simplified:\\n{summary.simplified_text}\")\n",
    "        print(f\"\\nüîÑ Analogy:\\n{summary.analogy}\")\n",
    "        print(f\"\\nüí° Example:\\n{summary.example}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    return final_state\n",
    "\n",
    "print(\"‚úì Interactive testing function ready\")\n",
    "print(\"\\nüí° Usage: run_agent_with_feedback('Your Topic Here', max_attempts=3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.7 Example: Test with a Topic\n",
    "\n",
    "Try the feedback loop! You'll be prompted to approve or regenerate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ STARTING FEEDBACK LOOP AGENT\n",
      "======================================================================\n",
      "Topic: BaseModel in LLM\n",
      "Max Attempts: 3\n",
      "======================================================================\n",
      "\n",
      "\n",
      "--- Attempt #1: Generating Summary for 'BaseModel in LLM' ---\n",
      "‚úì Summary generated successfully (Attempt #1)\n",
      "\n",
      "============================================================\n",
      "üìã GENERATED EXPLANATION\n",
      "============================================================\n",
      "\n",
      "üéØ Topic: BaseModel in LLM\n",
      "\n",
      "üìù Simplified Explanation:\n",
      "A BaseModel in a Large Language Model (LLM) is like the foundation of a building. It provides the basic structure and rules that help the model understand and generate language. Just like a building needs a strong base to support everything above it, an LLM needs a good BaseModel to work well.\n",
      "\n",
      "üîÑ Analogy:\n",
      "Think of the BaseModel as the recipe for a cake. The recipe gives you the basic instructions and ingredients you need to bake the cake. Without it, you wouldn't know how to mix the ingredients or how long to bake it. Similarly, the BaseModel provides the essential guidelines for the LLM to understand and create text.\n",
      "\n",
      "üí° Example:\n",
      "Imagine a BaseModel that has learned from a huge collection of books and articles. When you ask it to write a story, it uses what it learned from the BaseModel to create sentences that make sense, just like a chef uses a recipe to bake a delicious cake.\n",
      "\n",
      "============================================================\n",
      "Attempt 1 of 3\n",
      "============================================================\n",
      "\n",
      "üîÑ Regenerating with improvements...\n",
      "\n",
      "--- Router: Processing feedback 'regenerate' (Attempt 1/3) ---\n",
      "‚Üí Routing back to GENERATE (regenerate)\n",
      "\n",
      "--- Attempt #2: Generating Summary for 'BaseModel in LLM' ---\n",
      "‚úì Summary generated successfully (Attempt #2)\n",
      "\n",
      "============================================================\n",
      "üìã GENERATED EXPLANATION\n",
      "============================================================\n",
      "\n",
      "üéØ Topic: BaseModel in LLM\n",
      "\n",
      "üìù Simplified Explanation:\n",
      "A BaseModel in a Large Language Model (LLM) is like the core engine of a car. It powers everything and helps the car move smoothly. Without it, the car wouldn't work properly.\n",
      "\n",
      "üîÑ Analogy:\n",
      "Imagine a BaseModel as the main character in a story. Just like the main character drives the plot and connects all the other characters, the BaseModel is the central part of the LLM that helps it understand and generate language.\n",
      "\n",
      "üí° Example:\n",
      "For instance, think of a BaseModel like the brain of a robot. If you want the robot to understand commands and respond intelligently, it needs a well-designed brain (the BaseModel) to process information and learn from it.\n",
      "\n",
      "============================================================\n",
      "Attempt 2 of 3\n",
      "============================================================\n",
      "\n",
      "üîÑ Regenerating with improvements...\n",
      "\n",
      "--- Router: Processing feedback 'regenerate' (Attempt 2/3) ---\n",
      "‚Üí Routing back to GENERATE (regenerate)\n",
      "\n",
      "--- Attempt #3: Generating Summary for 'BaseModel in LLM' ---\n",
      "‚úì Summary generated successfully (Attempt #3)\n",
      "\n",
      "============================================================\n",
      "üìã GENERATED EXPLANATION\n",
      "============================================================\n",
      "\n",
      "üéØ Topic: BaseModel in LLM\n",
      "\n",
      "üìù Simplified Explanation:\n",
      "A BaseModel in a Large Language Model (LLM) is like the main toolbox for a builder. It contains all the essential tools and parts needed to create different structures, like houses or bridges, but it doesn't build them by itself. Instead, it provides the foundation and resources that other models can use to create specific things, like answering questions or writing stories.\n",
      "\n",
      "üîÑ Analogy:\n",
      "Think of the BaseModel as the engine of a train. The engine is crucial because it provides the power and direction for the train, but it‚Äôs the train cars that carry passengers or cargo to their destinations. Similarly, the BaseModel powers the LLM, while other components help it perform specific tasks like generating text or translating languages.\n",
      "\n",
      "üí° Example:\n",
      "For instance, imagine a BaseModel trained on a vast amount of text data. When you ask it to write a poem, it uses its foundational knowledge to understand language patterns and styles, just like a train engine pulls different cars to deliver various types of goods to different places.\n",
      "\n",
      "============================================================\n",
      "Attempt 3 of 3\n",
      "============================================================\n",
      "\n",
      "‚úÖ Explanation approved!\n",
      "\n",
      "--- Router: Processing feedback 'yes' (Attempt 3/3) ---\n",
      "‚Üí Routing to END (approved)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "üìä FINAL RESULTS\n",
      "======================================================================\n",
      "\n",
      "‚úì Total Attempts: 3\n",
      "‚úì Final Decision: yes\n",
      "\n",
      "üìú CONVERSATION HISTORY:\n",
      "\n",
      "  Attempt 1:\n",
      "    Feedback: regenerate\n",
      "    Notes: Make the Explanation more code oriented\n",
      "\n",
      "  Attempt 2:\n",
      "    Feedback: regenerate\n",
      "    Notes: More detailed explanation\n",
      "\n",
      "  Attempt 3:\n",
      "    Feedback: approved\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚úÖ APPROVED EXPLANATION\n",
      "======================================================================\n",
      "\n",
      "üéØ Topic: BaseModel in LLM\n",
      "\n",
      "üìù Simplified:\n",
      "A BaseModel in a Large Language Model (LLM) is like the main toolbox for a builder. It contains all the essential tools and parts needed to create different structures, like houses or bridges, but it doesn't build them by itself. Instead, it provides the foundation and resources that other models can use to create specific things, like answering questions or writing stories.\n",
      "\n",
      "üîÑ Analogy:\n",
      "Think of the BaseModel as the engine of a train. The engine is crucial because it provides the power and direction for the train, but it‚Äôs the train cars that carry passengers or cargo to their destinations. Similarly, the BaseModel powers the LLM, while other components help it perform specific tasks like generating text or translating languages.\n",
      "\n",
      "üí° Example:\n",
      "For instance, imagine a BaseModel trained on a vast amount of text data. When you ask it to write a poem, it uses its foundational knowledge to understand language patterns and styles, just like a train engine pulls different cars to deliver various types of goods to different places.\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the feedback loop\n",
    "result = run_agent_with_feedback(\"BaseModel in LLM\", max_attempts=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
